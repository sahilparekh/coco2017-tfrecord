{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir=<Path to coco2017 dataset>\n",
    "dataType='train2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO categories: \n",
      "person bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair drier toothbrush\n",
      "\n",
      "COCO supercategories: \n",
      "vehicle sports electronic food accessory animal outdoor appliance person furniture kitchen indoor\n"
     ]
    }
   ],
   "source": [
    "# display COCO categories and supercategories\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'name': 'person', 'supercategory': 'person'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all images containing given categories, select one at random\n",
    "catIds = coco.getCatIds(catNms=['vehicle']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgIds = coco.getImgIds(catIds=catIds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118287"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person : 64115\n",
      "car : 12251\n",
      "truck : 6127\n",
      "bench : 5570\n",
      "backpack : 5528\n",
      "handbag : 6841\n",
      "bottle : 8501\n",
      "cup : 9189\n",
      "bowl : 7111\n",
      "chair : 12774\n",
      "dining table : 11837\n",
      "cell phone : 4803\n",
      "sink : 4678\n",
      "book : 5332\n",
      "clock : 4659\n",
      "Total Categories : 15\n"
     ]
    }
   ],
   "source": [
    "cats_to_pack = []\n",
    "cat_img = {}\n",
    "cat_counter = 1 # leave zero for background class\n",
    "for cat in cats:\n",
    "    imgIds = coco.getImgIds(catIds=[cat['id']])\n",
    "    if len(imgIds) > 4561:\n",
    "        cats_to_pack.append(cat['name'])\n",
    "        cat_img[cat['name']] = {\"imgids\":imgIds, \"catid\":cat_counter, \"cat_ogid\":cat['id']}\n",
    "        cat_counter += 1\n",
    "        print('{0} : {1}'.format(cat['name'], len(imgIds)))\n",
    "cat_counter -= 1\n",
    "print(\"Total Categories : {}\".format(cat_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I wanted max object instances for any 15 categories so i choosed uppercap on number of instances of object\n",
    "#you may have your own criteria\n",
    "upper_cap = 4600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501\n",
      "6127\n",
      "6841\n",
      "4659\n",
      "12251\n",
      "4678\n",
      "11837\n",
      "64115\n",
      "4803\n",
      "5528\n",
      "9189\n",
      "5570\n",
      "7111\n",
      "5332\n",
      "12774\n"
     ]
    }
   ],
   "source": [
    "selected_imgs = {}\n",
    "#randomly select upper cap images\n",
    "#select random instances of object but kept similar number of objects per class to avoid overweighing of single class \n",
    "for cat_name, val in cat_img.items():\n",
    "    img_ids = val[\"imgids\"]\n",
    "    print(len(img_ids))\n",
    "    random.shuffle(img_ids)\n",
    "    random.shuffle(img_ids)\n",
    "    selected_imgs[cat_name] = {\"imgids\":img_ids[:upper_cap], \"catid\":val[\"catid\"], \"cat_ogid\":val['cat_ogid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_record_creation_util import open_sharded_output_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCoder(object):\n",
    "    \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create a single Session to run all image coding calls.\n",
    "        self._sess = tf.Session()\n",
    "\n",
    "        # Initializes function that converts PNG to JPEG data.\n",
    "        self._png_data = tf.placeholder(dtype=tf.string)\n",
    "        image = tf.image.decode_png(self._png_data, channels=3)\n",
    "        self._png_to_jpeg = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "        # Initializes function that converts CMYK JPEG data to RGB JPEG data.\n",
    "        self._cmyk_data = tf.placeholder(dtype=tf.string)\n",
    "        image = tf.image.decode_jpeg(self._cmyk_data, channels=0)\n",
    "        self._cmyk_to_rgb = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "        # Initializes function that decodes RGB JPEG data.\n",
    "        self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "        self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "    def png_to_jpeg(self, image_data):\n",
    "        return self._sess.run(self._png_to_jpeg,\n",
    "                          feed_dict={self._png_data: image_data})\n",
    "\n",
    "    def cmyk_to_rgb(self, image_data):\n",
    "        return self._sess.run(self._cmyk_to_rgb,\n",
    "                          feed_dict={self._cmyk_data: image_data})\n",
    "\n",
    "    def decode_jpeg(self, image_data):\n",
    "        image = self._sess.run(self._decode_jpeg,\n",
    "                               feed_dict={self._decode_jpeg_data: image_data})\n",
    "        assert len(image.shape) == 3\n",
    "        assert image.shape[2] == 3\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_or_create_dir(directory):\n",
    "    \"\"\"Check if directory exists otherwise create it.\"\"\"\n",
    "    if not tf.gfile.Exists(directory):\n",
    "        tf.gfile.MakeDirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(image,\n",
    "                      annotations_list,\n",
    "                      image_dir,\n",
    "                      category_index,\n",
    "                      include_masks=False):\n",
    "    \"\"\"Converts image and annotations to a tf.Example proto.\n",
    "    Args:\n",
    "    image: dict with keys:\n",
    "      [u'license', u'file_name', u'coco_url', u'height', u'width',\n",
    "      u'date_captured', u'flickr_url', u'id']\n",
    "    annotations_list:\n",
    "      list of dicts with keys:\n",
    "      [u'segmentation', u'area', u'iscrowd', u'image_id',\n",
    "      u'bbox', u'category_id', u'id']\n",
    "      Notice that bounding box coordinates in the official COCO dataset are\n",
    "      given as [x, y, width, height] tuples using absolute coordinates where\n",
    "      x, y represent the top-left (0-indexed) corner.  This function converts\n",
    "      to the format expected by the Tensorflow Object Detection API (which is\n",
    "      which is [ymin, xmin, ymax, xmax] with coordinates normalized relative\n",
    "      to image size).\n",
    "    image_dir: directory containing the image files.\n",
    "    category_index: a dict containing COCO category information keyed\n",
    "      by the 'id' field of each category.  See the\n",
    "      label_map_util.create_category_index function.\n",
    "    include_masks: Whether to include instance segmentations masks\n",
    "      (PNG encoded) in the result. default: False.\n",
    "    Returns:\n",
    "    example: The converted tf.Example\n",
    "    num_annotations_skipped: Number of (invalid) annotations that were ignored.\n",
    "    Raises:\n",
    "    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n",
    "    \"\"\"\n",
    "    image_height = image['height']\n",
    "    image_width = image['width']\n",
    "    filename = image['file_name']\n",
    "    image_id = image['id']\n",
    "\n",
    "    full_path = os.path.join(image_dir, filename)\n",
    "    with tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    xmin = []\n",
    "    xmax = []\n",
    "    ymin = []\n",
    "    ymax = []\n",
    "    is_crowd = []\n",
    "    category_names = []\n",
    "    category_ids = []\n",
    "    area = []\n",
    "    encoded_mask_png = []\n",
    "    num_annotations_skipped = 0\n",
    "    for object_annotations in annotations_list:\n",
    "        (x, y, width, height) = tuple(object_annotations['bbox'])\n",
    "        if width <= 0 or height <= 0:\n",
    "            num_annotations_skipped += 1\n",
    "            continue\n",
    "        if x + width > image_width or y + height > image_height:\n",
    "            num_annotations_skipped += 1\n",
    "            continue\n",
    "        xmin.append(float(x) / image_width)\n",
    "        xmax.append(float(x + width) / image_width)\n",
    "        ymin.append(float(y) / image_height)\n",
    "        ymax.append(float(y + height) / image_height)\n",
    "        is_crowd.append(object_annotations['iscrowd'])\n",
    "        category_id = int(object_annotations['category_id'])\n",
    "        category_ids.append(category_id)\n",
    "        category_names.append(category_index[category_id]['name'].encode('utf8'))\n",
    "        area.append(object_annotations['area'])\n",
    "\n",
    "        if include_masks:\n",
    "            run_len_encoding = mask.frPyObjects(object_annotations['segmentation'],\n",
    "                                              image_height, image_width)\n",
    "            binary_mask = mask.decode(run_len_encoding)\n",
    "            if not object_annotations['iscrowd']:\n",
    "                binary_mask = np.amax(binary_mask, axis=2)\n",
    "            pil_image = PIL.Image.fromarray(binary_mask)\n",
    "            output_io = io.BytesIO()\n",
    "            pil_image.save(output_io, format='PNG')\n",
    "            encoded_mask_png.append(output_io.getvalue())\n",
    "            \n",
    "    feature_dict = {\n",
    "      'image/height':\n",
    "          int64_feature(image_height),\n",
    "      'image/width':\n",
    "          int64_feature(image_width),\n",
    "      'image/filename':\n",
    "          bytes_feature(filename.encode('utf8')),\n",
    "      'image/source_id':\n",
    "          bytes_feature(str(image_id).encode('utf8')),\n",
    "      'image/key/sha256':\n",
    "          bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded':\n",
    "          bytes_feature(encoded_jpg),\n",
    "      'image/format':\n",
    "          bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin':\n",
    "          float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax':\n",
    "          float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin':\n",
    "          float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax':\n",
    "          float_list_feature(ymax),\n",
    "      'image/object/class/id':\n",
    "          int64_list_feature(category_ids),\n",
    "      'image/object/class/text':\n",
    "          bytes_list_feature(category_names),\n",
    "      'image/object/is_crowd':\n",
    "          int64_list_feature(is_crowd),\n",
    "      'image/object/area':\n",
    "          float_list_feature(area),\n",
    "    }\n",
    "    \n",
    "    if include_masks:\n",
    "        feature_dict['image/object/mask'] = (\n",
    "            bytes_list_feature(encoded_mask_png))\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return key, example, num_annotations_skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47705\n",
      "[44, 8, 31, 3, 81, 67, 1, 77, 47, 27, 51, 15, 85, 84, 62]\n",
      "[7, 3, 6, 2, 13, 11, 1, 12, 8, 5, 9, 4, 15, 14, 10]\n",
      "{51: 9, 67: 11, 1: 1, 8: 3, 15: 4, 44: 7, 77: 12, 47: 8, 81: 13, 3: 2, 84: 14, 85: 15, 27: 5, 62: 10, 31: 6}\n",
      "{1: 'person', 2: 'car', 3: 'truck', 4: 'bench', 5: 'backpack', 6: 'handbag', 7: 'bottle', 8: 'cup', 9: 'bowl', 10: 'chair', 11: 'dining table', 12: 'cell phone', 13: 'sink', 14: 'book', 15: 'clock'}\n",
      "{1: {'id': 1, 'name': 'person'}, 2: {'id': 2, 'name': 'car'}, 3: {'id': 3, 'name': 'truck'}, 4: {'id': 4, 'name': 'bench'}, 5: {'id': 5, 'name': 'backpack'}, 6: {'id': 6, 'name': 'handbag'}, 7: {'id': 7, 'name': 'bottle'}, 8: {'id': 8, 'name': 'cup'}, 9: {'id': 9, 'name': 'bowl'}, 10: {'id': 10, 'name': 'chair'}, 11: {'id': 11, 'name': 'dining table'}, 12: {'id': 12, 'name': 'cell phone'}, 13: {'id': 13, 'name': 'sink'}, 14: {'id': 14, 'name': 'book'}, 15: {'id': 15, 'name': 'clock'}}\n"
     ]
    }
   ],
   "source": [
    "tot_img_ids = []\n",
    "tot_og_catids = []\n",
    "tot_catids = []\n",
    "id_lbl_map = {}\n",
    "old_new_id_map = {}\n",
    "category_index = {}\n",
    "for cat_name, val in selected_imgs.items():\n",
    "    tot_img_ids += val['imgids']\n",
    "    tot_og_catids += [val['cat_ogid']]\n",
    "    tot_catids += [val['catid']]\n",
    "    id_lbl_map[val['catid']] = cat_name\n",
    "    old_new_id_map[val['cat_ogid']] = val['catid']\n",
    "    category_index[val['catid']] = {'id': val['catid'], 'name':cat_name}\n",
    "    \n",
    "tot_img_ids = list(set(tot_img_ids))\n",
    "random.shuffle(tot_img_ids)\n",
    "print(len(tot_img_ids))\n",
    "print(tot_og_catids)\n",
    "print(tot_catids)\n",
    "print(old_new_id_map)\n",
    "print(id_lbl_map)\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pbtxthelper as pbh\n",
    "import io\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kt-gpu2/My Passport/Datasets/coco2017/train2017\n",
      "{'id': 1, 'name': 'person'}\n",
      "{'id': 2, 'name': 'car'}\n",
      "{'id': 3, 'name': 'truck'}\n",
      "{'id': 4, 'name': 'bench'}\n",
      "{'id': 5, 'name': 'backpack'}\n",
      "{'id': 6, 'name': 'handbag'}\n",
      "{'id': 7, 'name': 'bottle'}\n",
      "{'id': 8, 'name': 'cup'}\n",
      "{'id': 9, 'name': 'bowl'}\n",
      "{'id': 10, 'name': 'chair'}\n",
      "{'id': 11, 'name': 'dining table'}\n",
      "{'id': 12, 'name': 'cell phone'}\n",
      "{'id': 13, 'name': 'sink'}\n",
      "{'id': 14, 'name': 'book'}\n",
      "{'id': 15, 'name': 'clock'}\n",
      "Written pbtxt file\n",
      "Processed 0 images...\n",
      "Processed 1000 images...\n",
      "Processed 2000 images...\n",
      "Processed 3000 images...\n",
      "Processed 4000 images...\n",
      "Processed 5000 images...\n",
      "Processed 6000 images...\n",
      "Processed 7000 images...\n",
      "Processed 8000 images...\n",
      "Processed 9000 images...\n",
      "Processed 10000 images...\n",
      "Processed 11000 images...\n",
      "Processed 12000 images...\n",
      "Processed 13000 images...\n",
      "Processed 14000 images...\n",
      "Processed 15000 images...\n",
      "Processed 16000 images...\n",
      "Processed 17000 images...\n",
      "Processed 18000 images...\n",
      "Processed 19000 images...\n",
      "Processed 20000 images...\n",
      "Processed 21000 images...\n",
      "Processed 22000 images...\n",
      "Processed 23000 images...\n",
      "Processed 24000 images...\n",
      "Processed 25000 images...\n",
      "Processed 26000 images...\n",
      "Processed 27000 images...\n",
      "Processed 28000 images...\n",
      "Processed 29000 images...\n",
      "Processed 30000 images...\n",
      "Processed 31000 images...\n",
      "Processed 32000 images...\n",
      "Processed 33000 images...\n",
      "Processed 34000 images...\n",
      "Processed 35000 images...\n",
      "Processed 36000 images...\n",
      "Processed 37000 images...\n",
      "Processed 38000 images...\n",
      "Processed 39000 images...\n",
      "Processed 40000 images...\n",
      "Processed 41000 images...\n",
      "Processed 42000 images...\n",
      "Processed 43000 images...\n",
      "Processed 44000 images...\n",
      "Processed 45000 images...\n",
      "Processed 46000 images...\n",
      "Processed 47000 images...\n"
     ]
    }
   ],
   "source": [
    "pbtxt = 'labels.pbtxt'\n",
    "output_dir = 'train_output'\n",
    "num_of_shards  = 10\n",
    "input_images_directory = os.path.join(dataDir, dataType)\n",
    "print(input_images_directory)\n",
    "\n",
    "#create labels pbtxt\n",
    "pbh.dictToPbtxt(category_index, pbtxt)\n",
    "base_pth = os.path.join(output_dir, dataType)\n",
    "\n",
    "# sys.exit(1)\n",
    "_check_or_create_dir(output_dir)\n",
    "#Returns Tfrecords\n",
    "with contextlib2.ExitStack() as tf_record_close_stack:\n",
    "    output_tfrecords = open_sharded_output_tfrecords(\n",
    "        tf_record_close_stack, output_dir,\n",
    "        num_of_shards)\n",
    "    \n",
    "    for counter, img_id in enumerate(tot_img_ids):\n",
    "        if (counter % 1000) == 0:\n",
    "            print('Processed {} images...'.format(counter))\n",
    "        \n",
    "        img_annotations = coco.getAnnIds(imgIds=[img_id])\n",
    "        img_annotations = coco.loadAnns(img_annotations)\n",
    "#         print(img_annotations[0])\n",
    "        new_anns = [x for x in img_annotations if x['category_id'] in tot_og_catids]\n",
    "        for ann in new_anns:\n",
    "#             print(ann)\n",
    "            v = ann['category_id']\n",
    "            ann['category_id'] = old_new_id_map[ann['category_id']]\n",
    "#             print('changed {0} from {1}'.format(ann['category_id'], v))\n",
    "            \n",
    "        img_data = coco.loadImgs([img_id])\n",
    "#         print(new_anns)\n",
    "#         img_path = os.path.join(input_images_directory, img_data[0]['file_name'])\n",
    "#         print(img_path)\n",
    "#         print(os.path.isfile(img_path))\n",
    "        \n",
    "        \n",
    "        key, tf_example, num_annotations_skipped = create_tf_example(image=img_data[0],\n",
    "                                                                     annotations_list=new_anns,\n",
    "                                                                     image_dir=input_images_directory,\n",
    "                                                                     category_index=category_index\n",
    "                                                                     )\n",
    "        if tf_example:\n",
    "            shard_idx = int(img_id) % num_of_shards\n",
    "            output_tfrecords[shard_idx].write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.48s)\n",
      "creating index...\n",
      "index created!\n",
      "person : 2693\n",
      "car : 535\n",
      "truck : 250\n",
      "bench : 235\n",
      "backpack : 228\n",
      "handbag : 292\n",
      "bottle : 379\n",
      "cup : 390\n",
      "bowl : 314\n",
      "chair : 580\n",
      "dining table : 501\n",
      "cell phone : 214\n",
      "sink : 187\n",
      "book : 230\n",
      "clock : 204\n",
      "Total Categories : 15\n",
      "379\n",
      "250\n",
      "292\n",
      "204\n",
      "535\n",
      "187\n",
      "501\n",
      "2693\n",
      "214\n",
      "228\n",
      "390\n",
      "235\n",
      "314\n",
      "230\n",
      "580\n"
     ]
    }
   ],
   "source": [
    "dataType='val2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "coco=COCO(annFile)\n",
    "\n",
    "cats_to_pack = []\n",
    "cat_img = {}\n",
    "cat_counter = 1 # leave zero for background class\n",
    "for cat in cats:\n",
    "    if cat['id'] in tot_og_catids:\n",
    "        imgIds = coco.getImgIds(catIds=[cat['id']])\n",
    "        cats_to_pack.append(cat['name'])\n",
    "        cat_img[cat['name']] = {\"imgids\":imgIds, \"catid\":cat_counter, \"cat_ogid\":cat['id']}\n",
    "        cat_counter += 1\n",
    "        print('{0} : {1}'.format(cat['name'], len(imgIds)))\n",
    "cat_counter -= 1\n",
    "print(\"Total Categories : {}\".format(cat_counter))\n",
    "\n",
    "selected_imgs = {}\n",
    "#randomly select upper cap images\n",
    "for cat_name, val in cat_img.items():\n",
    "    img_ids = val[\"imgids\"]\n",
    "    print(len(img_ids))\n",
    "    random.shuffle(img_ids)\n",
    "    random.shuffle(img_ids)\n",
    "    selected_imgs[cat_name] = {\"imgids\":img_ids, \"catid\":val[\"catid\"], \"cat_ogid\":val['cat_ogid']}\n",
    "    \n",
    "tot_img_ids = []\n",
    "for cat_name, val in selected_imgs.items():\n",
    "    tot_img_ids += val['imgids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kt-gpu2/My Passport/Datasets/coco2017/val2017\n",
      "{'id': 1, 'name': 'person'}\n",
      "{'id': 2, 'name': 'car'}\n",
      "{'id': 3, 'name': 'truck'}\n",
      "{'id': 4, 'name': 'bench'}\n",
      "{'id': 5, 'name': 'backpack'}\n",
      "{'id': 6, 'name': 'handbag'}\n",
      "{'id': 7, 'name': 'bottle'}\n",
      "{'id': 8, 'name': 'cup'}\n",
      "{'id': 9, 'name': 'bowl'}\n",
      "{'id': 10, 'name': 'chair'}\n",
      "{'id': 11, 'name': 'dining table'}\n",
      "{'id': 12, 'name': 'cell phone'}\n",
      "{'id': 13, 'name': 'sink'}\n",
      "{'id': 14, 'name': 'book'}\n",
      "{'id': 15, 'name': 'clock'}\n",
      "Written pbtxt file\n",
      "Processed 0 images...\n",
      "Processed 1000 images...\n",
      "Processed 2000 images...\n",
      "Processed 3000 images...\n",
      "Processed 4000 images...\n",
      "Processed 5000 images...\n",
      "Processed 6000 images...\n",
      "Processed 7000 images...\n"
     ]
    }
   ],
   "source": [
    "#val tfrecord\n",
    "pbtxt = 'labels.pbtxt'\n",
    "output_dir = 'val_output'\n",
    "num_of_shards  = 10\n",
    "input_images_directory = os.path.join(dataDir, dataType)\n",
    "print(input_images_directory)\n",
    "\n",
    "base_pth = os.path.join(output_dir, dataType)\n",
    "\n",
    "# sys.exit(1)\n",
    "_check_or_create_dir(output_dir)\n",
    "#Returns Tfrecords\n",
    "with contextlib2.ExitStack() as tf_record_close_stack:\n",
    "    output_tfrecords = open_sharded_output_tfrecords(\n",
    "        tf_record_close_stack, output_dir,\n",
    "        num_of_shards)\n",
    "    \n",
    "    for counter, img_id in enumerate(tot_img_ids):\n",
    "        if (counter % 1000) == 0:\n",
    "            print('Processed {} images...'.format(counter))\n",
    "        \n",
    "        img_annotations = coco.getAnnIds(imgIds=[img_id])\n",
    "        img_annotations = coco.loadAnns(img_annotations)\n",
    "#         print(img_annotations[0])\n",
    "        new_anns = [x for x in img_annotations if x['category_id'] in tot_og_catids]\n",
    "        for ann in new_anns:\n",
    "#             print(ann)\n",
    "            v = ann['category_id']\n",
    "            ann['category_id'] = old_new_id_map[ann['category_id']]\n",
    "#             print('changed {0} from {1}'.format(ann['category_id'], v))\n",
    "            \n",
    "        img_data = coco.loadImgs([img_id])\n",
    "#         print(new_anns)\n",
    "#         img_path = os.path.join(input_images_directory, img_data[0]['file_name'])\n",
    "#         print(img_path)\n",
    "#         print(os.path.isfile(img_path))\n",
    "        \n",
    "        \n",
    "        key, tf_example, num_annotations_skipped = create_tf_example(image=img_data[0],\n",
    "                                                                     annotations_list=new_anns,\n",
    "                                                                     image_dir=input_images_directory,\n",
    "                                                                     category_index=category_index\n",
    "                                                                     )\n",
    "        if tf_example:\n",
    "            shard_idx = int(img_id) % num_of_shards\n",
    "            output_tfrecords[shard_idx].write(tf_example.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
